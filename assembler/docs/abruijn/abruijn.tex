\documentclass[12pt]{article}

\usepackage{amssymb,amsmath,amsthm}
\usepackage{graphicx}
%\usepackage{fullpage}
\usepackage[final,colorlinks,hyperindex,unicode=true]{hyperref}
%\usepackage{tikz}
\usepackage{pgfplots}
\usepackage[shadow,colorinlistoftodos,textwidth=4cm]{todonotes}
%\usepackage{fullpage}

%\newcommand{\jpgpic}[1]{\begin{center}\includegraphics[width=\textwidth]{#1.jpg}\end{center}}

\begin{document}
\author{M. Dvorkin, A. Kulikov}
%\title{A Bruijn Graph Approach}
%\title{Seeded assembly graph approach to {\it de novo} genome assembly}
\title{Earmark graph approach to {\it de novo} genome assembly}
\maketitle

\begin{abstract}
A common approach to assembling a genome from short reads is constructing
the de Bruijn graph on all $k$-mers from the given set of reads and finding a traversal of edges
in this graph. We propose a new approach that allows to decrease
the graph size without losing the essential information from the input data.
Instead of using all the $k$-mers from a given read we take only a few of them
(and call them ``earmarked''). Besides an obvious advantage of requiring less memory 
and time for constructing, the resulting earmark graph has several other advantages over the
de Bruijn graph. We discuss them in the paper and also present some experimental results.
\end{abstract}

%\listoftodos
\tableofcontents

%\newpage

\section{Introduction}
A common approach to assembling a genome from short reads is constructing
the de Bruijn graph \cite{PW01} on all $k$-mers from the given set of 
reads and finding a traversal of edges in this graph.{\todo{do we need a definition 
of the de Bruijn graph here?}}
%Namely, the set of all $k$-mers form the set of vertices of the graph
%and two $k$-mers $A$ and $B$ are joined by a directed edge if there is a read
%where the $k$-mer $B$ appears 
An example of the de Bruijn graph for $k=3$ and a set of all reads of length $6$
of a (circular) genome $g={\tt ATGCATTGCACTGCA}$ is given in Fig.~\ref{fig:debruijn}a
(multiple edges are shown as just one edge). The genome corresponds to an Eulerian
cycle in the de Bruijn graph.

\begin{figure}
\caption{The de Bruijn graph (a) and earmark graph (b) built on $3$-mers 
of all $6$-reads of a toy genome {\tt ATGCATTGCACTGCA}.}\label{fig:debruijn}
\begin{center}
a\includegraphics[width=0.9\textwidth]{ATGCATTGCACTGCA_debruijn.pdf}\\
b\includegraphics[width=0.9\textwidth]{ATGCATTGCACTGCA_earmark.pdf}\\
%\includegraphics[width=0.9\textwidth]{ATGCATTGCACTGCA_earmark2.pdf}\\
\end{center}
\end{figure}

The size of the de Bruijn graph for most of the genomes is huge making
it difficult to process. 
We propose a new approach that allows to decrease
the graph size without losing the essential information from the input data.
Instead of using all the $k$-mers from a given read we take only a few of them
(and call them \emph{earmarked}).
Namely, instead 
of representing each read as a sequence of edges 
between its consecutive $k$-mers (in which case a read of length $r$ defines
$r-k-1$ edges) we represent it as just one (or a few, in general)
edge between some of its $k$-mers. For example, for 
reads {\tt ACGTACT} and {\tt TACTAGC} and $k=3$
instead of all gray edges in the figure below we will have 
only two black edges.
\begin{center}
\includegraphics[width=0.9\textwidth]{fig1.pdf}
\end{center}
We call the resulting graph built on earmarked $k$-mers \emph{an earmark graph}.
It is a special case of A-Bruijn graph introduced by Pevzner, Tang, and Tesler \cite{PTG04}.
Besides an obvious advantage of requiring less memory 
and time for constructing, the resulting earmark graph has several other advantages over the
de Bruijn graph. We discuss them after all the necessary definitions.

Our approach is inspired by the work by Roberts et al. \cite{RW04} on sequence comparison.
The problem they studied is a pairwise comparison of a set of strings. 
One of the approaches to this problem is the seed-and-extend approach.
One first stores the set of all possible $k$-mers from a given set of strings.
Then, only pairs of strings that both have the same $k$-mer as a substring are compared.
This allows to avoid comparing all pairs of input strings. However the database
of all $k$-mers may be really huge. To reduce the storage requirements Roberts et al. propose
to select not all the $k$-mers, but only those that a minimal in an input string w.r.t.
to a certain order. Such $k$-mers are called \emph{minimizers}.



\section{Earmark graph}

%\subsection{Definition}

\section{Pseudocode of the assembler}
In this section, we give a high-level description of the main parts of the assembler.

Iterative procedure for selecting the set of earmarked $k$-mers is the following:

\begin{enumerate}
\item From each read, select $t$ minimum hash values of its $k$-mers, add them to the global set of earmarked hash values.
\item (optional, if $t=1$) For each read that has only one k-mer with earmarked hash value, earmark one more k-mer from this read.
\item In each read, select $k$-mers that have their hash values earmarked.
For corresponding vertices in the resulting A Bruijn graph, add all pairwise edges, storing their lengths.
%\item For each $k$-mer that has no left or right neighbours, find a neighbour on the corresponding side
%that has the smallest hash value and earmark it.
%\item Repeat the previous step to minimize the number of neighbourless $k$-mers.
\end{enumerate}

This procedure results with an A-Bruijn graph that is subject to further processing.

\subsection{Tip extension procedure}

Due to the fact that not all the k-mers are represented in the A-Bruijn graph,
some extra gaps can be unwillingly created.
Consider a genome substring $abcde$, where $b$ and $d$ a k-mers that have small hash values and are selected as minimizers.
If none of the reads in the input data contain the whole substring $bcd$, then vertices corresponding to
$b$ and $d$ will be tips in the A-Bruijn graph.
Meanwhile reads containing $abc$ and $cde$ may be present in the input data, thus it is an error of the approach
to call this vertices tips and to introduce a gap here.

The tip extension procedure is suggested to handle this issue.
It consists of three steps that are repeated consequently until no possible tip extensions are present.
(Each steps demands reading the entire input data. It is possible to reduce the procedure to less than three
steps, but much more memory will be used in that case).

\begin{enumerate}
\item By processing all the reads, find out for each earmarked k-mer, whether we've seen any
earmarked $k$-mer to the left from it, and to the right of it.
Those earmarked k-mers that don't have either left or right "neighbours" are called tips --
(left tips and right tips correspondingly).
\item By processing all the reads, find the collection of all the non-earmarked k-mers that
are present (at least once) in a read to the left of a left tip, or to the right of the right tip.
Call them possible tip extensions.
\item By processing all the reads, for each possible tip extension, record whether there was
any earmarked k-mers to the left from it, and to the right of it.
\end{enumerate}

Now that this information is collected, each tip is being extended with
a possible tip extension using the following rules (in the order preference):

\begin{enumerate}
\item Check if any of its possible tip extensions was already selected as an earmark
(As a tip extension for some previously processed tip, using rules 2 and 3 below).
If so, continue to the next tip.
\item Check if any of its possible tip extensions has both left and right neighbours.
We select this extension as an earmark and thus eliminate at least one undesirable tip.
\item Select as an earmark the possible tip extension that is most distant (in base pairs)
from the tip being proccesed. Doing this, we don't eliminate a tip but we extend in as far
as possible. This helps us not to lose information near the actual gaps (or thes end of actual scaffolds).
\end{enumerate}

If no new earmarked k-mers were introduced after this procedure, stop, otherwise repeat the entire procedure.

\section{Practical results}
\todo[inline]{to be written}



\section{Discussion and further ideas}


\todo[inline]{clean up the references}
\bibliographystyle{alpha}
\bibliography{bib}

\end{document}

\subsection{Example}

\begin{figure}
\caption{De Bruijn (grey) and A Bruijn (black) graphs of genomes {\tt ACTGACTGTTGACACTG} ($readsize=9$, $k=5$)
and {\tt ATTGGTACATTGTGGTACGTACTGACT} ($readsize=11$, $k=5$).}\label{fig23}
\begin{center}\includegraphics[height=0.9\textheight]{fig2.pdf}
~~~~~~~~~~~~~~
\includegraphics[height=0.9\textheight]{fig3.pdf}\end{center}
\end{figure}

Fig.~\ref{fig23} shows de Bruijn (black edges) and A Bruijn (grey edges) graphs for two toy genomes 
{\tt ACTGACTGTTGACACTG} and {\tt ATTGGTACATTGTGGTACGTACTGACT}. Numbers on edges are their multiplicities. 
We assume that the genome is circular and that we are given the set of all its reads.


\subsection{Advantages of A Bruijn graph over de Bruijn graph}
\begin{enumerate}
\item Clearly, it requires less memory.
\item In general, we expect that the resulting A Bruijn graph 
will have the same structure as the corresponding condensed de Bruijn graph.
If so, this would allow us to construct the condensed de Bruijn graph
using less time and memory.
\item If the used hash-function respects frequency of $k$-mers
the resulting graph will contain a smaller fraction of erroneous $k$-mers.
\item If the hash function does not mark $k$-mers that appear too often, then 
some of the repeats will be already resolved in A Bruijn graph.

An example of this effect is given in Fig.~\ref{fig:different_orderings}
where two A Bruijn graphs of a genome {\tt TAAACGAAAC} ($readsize=6$, $k=3$) 
are shown. The difference is in the way $3$-mers are ordered. Green edges 
correspond to the standard lexicographic ordering ({\tt AAA}$<${\tt 
AAC}$<\dots<${\tt TTT}). Now note that the considered genome contains a 
repeat {\tt AAAC}. Assume that the hash function treats $3$-mers {\tt AAA}
and {\tt AAC} from this repeat as maximal. Namely, let the ordering be the 
following:
\[{\tt TAA}<{\tt ACG}<{\tt CGA}<{\tt GAA}<{\tt CTA}<{\tt ACT}<{\tt AAA}<{\tt AAC} \, .\]
As figure shows, this ordering gives a graph consisting of just one cycle.
A slightly more complicated example is given on Fig.~\ref{fig:different_orderings2}.
There, the corresponding genome {\tt ATGCATTGCACTGCA} contains a repeat {\tt TGCA}
three times. Hence de Bruijn graph spells at least two different genomes. 
%By a careful choice of 


\begin{figure}
\caption{A Bruijn graphs of genome {\tt TAAACGAAAC} ($readsize=6$, $k=3$)
for different orderings on $3$-mers.}\label{fig:different_orderings}
\begin{center}
\includegraphics[width=0.9\textwidth]{TAAACGAAAC.pdf}
\end{center}
\end{figure}

\begin{figure}
\caption{A Bruijn graphs of genome {\tt ATGCATTGCACTGCA} ($readsize=6$, $k=3$)
for different orderings on $3$-mers.}\label{fig:different_orderings2}
\begin{center}
\includegraphics[width=0.9\textwidth]{ATGCATTGCACTGCA.pdf}
\end{center}
\end{figure}

\item \dots \todo{what else?..}
\end{enumerate}

\subsection{Hash Functions}

One of the possibilities to extract two distinguished $k$-mers out of a given
read is to take two $k$-mers with minimal value of some hash function $h$.
Some natural properties that $h$ should hold are listed below.
\begin{enumerate}
  \item The hash function should be easily computed.
  While iterating through all $k$-mers of a given read
  it is also important to have a fast way to recompute 
  the hash value. For this, one may take a kind of polynomial
  hash function (like in a finger-printing algorithm for the pattern 
  matching problem).
  \item It should to be stable with respect to reverse-complementary 
  $k$-mers, i.e., $h(s) = h(s^{RC})$ so that if we represent a read
  by an edge $(s_1,s_2)$, then its reverse-complement read is represented by 
  a ``reverse'' edge $(s_2^{RC},s_1^{RC})$. Two natural ways to make out a
  reverse-complementary stable hash function $h$ out of any hash function 
  $h_0$ are the following:
  \[h(s) = h_0(s) \oplus h_0(s^{RC}) \textrm{ or } h(s) = \min\{h_0(s), h_0(s^{RC})\} .\]
\end{enumerate}


The main question that still needs to be answered is:
does this graph really represent the repeat structure of the genome?

\section{Practical results}

We've implemented the suggested approach and are currently investigating the resulting A Bruijn graphs
on emulated data sets.

The technical issues pushed us towards a two-pass procedure:
\begin{enumerate}
  \item Each read undergoes a (linear-time) hashing procedure, and two least-valued $k$-mers are marked as
  ``good''. (In fact, not themselves but their hash values are marked. Even if a few extra $k$-mers become
  good due to hash collisions, it will not make much harm).
  \item For each read, all of its $k$-mers are checked whether their hash values are good, and the good ones
  are mapped to corresponding vertices in the future graph. The read is thus counted towards one or more edges.
  The leavings (in the two ends of the read) are currently not considered.
\end{enumerate}

Fig.~\ref{fig4} shows the resulting A Bruijn graph for the first 10\% of the reference E. Coli genome; the ideal data set
was used for this calculation.

\begin{figure}
\caption{10\% of E. Coli genome. $K$ = 31. Two $k$-mers from each read.}\label{fig4}
\begin{center}\includegraphics[height=0.9\textheight]{fig4.pdf}\end{center}
\end{figure}

This graph has only undergone a simple vertex-merging procedure; there are more
yet-unimplemented simplifications applicable to this graph.

\subsection{Statistics}
The plot below shows the dependence of the number of vertices in a graph from the 
number of reads for {\tt s\_6.first10000}.

\begin{tikzpicture}
    \begin{axis}[xlabel={HTAKE},ylabel={$\#$ of vertices}]
    \addplot[smooth,mark=*,blue] plot coordinates { (1,1640) (2,2950) (3,4248) (4,5472) (5,6784)
      (10, 12028) (20, 15432) (25, 18642) (40, 19890) (50, 20052) (60, 20102) (75,20140) };
    %\addlegendentry{de Bruijn}
    \end{axis}
\end{tikzpicture}

The table below gives the number of vertices in a graph 
for two extreme values of {\tt HTAKE} (1 and 76) for {\tt s\_6.first10000}
(program version: Apr 25, 2011; $k=25$).


\begin{center}
\begin{tabular}{l|lll}
& \#bp=10000 & \#bp=100000 & \#bp=400000\\
\hline
${\tt HTAKE}=1$ & 1640 & 15916 & 62550\\
${\tt HTAKE}=76$ & 20144 & 202838 & 809730\\
ratio & $\approx 12.2$ & $\approx 12.7$ & $\approx 12.9$
\end{tabular}
\end{center}


\section{Further ideas}

\subsection{Making use of frequency}

The task of selecting the $k$-mers that will become vertices in the A Bruijn graph can be reformulated
as the task of selecting criteria that distinguish some $k$-mers among others that work the same way
in different reads.

Along with a hash function, an apt criterion is the frequency of the given $k$-mer among all reads
(provided the corresponding hash-table is memory-feasible). This criterion might be fruitful considering
the following.

\begin{itemize}
  \item The $k$-mers that are underrepresented
%  {\todo{what do we mean by ``underrepresented''?
%  is it true that most of the erroneous reads have frequency one?}}
  in the reads (even those a with small value of hash function)
  are (most probably) erroneous. Using frequency allows us 
  to exclude them from the set of
  vertex-forming $k$-mers.
  \item The $k$-mers that are overrepresented correspond to high-degree vertices in the graph.
  It might be helpful to exclude them as well in order to make the structure of the graph more feasible.
  (Motivation: consider two reads, $axyb$ and $cxyd$. A hash function might suggest to select $k$-mers $x$ and
  $y$ which would create a fork in the graph. Selecting $a$, $b$, $c$ and $d$ on the other hand leads to
  two separate edges.)
\end{itemize}

\subsection{Reducing the number of vertices}
As said in the beginning the main motivation for considering such graphs
is that they contain fewer edges than the original de Bruijn graph. Clearly, the number of edges in the
A Bruijn graph is also reduced (the vertices with no bold adjacent edges actually do not belong
to A Bruijn graph). In order to further reduce the number of vertices we can do the following.
First, mark just one $k$-mer in each read with the minimal possible hash value. If it turned out to be
the first or the last $k$-mer of the current read, mark one more $k$-mer with the next smallest hash 
value.

In the ideal case when each possible read is present in the set of reads, this guarantess that
at least two $k$-mers will be marked in each read.
In real situations it would be reasonable to take the second $k$-mer if the first one
falls into on of the leftmost or rightmost $\tau$ positions for some treshold $\tau$.

\subsection{Paired reads}

Each single read provides one or several edges with the information of the following kind:
the two end-vertices of this edge are likely to be present in the desired graph traversal
at the distance exactly $d$ from each other.

Meanwhile, paired reads provide the information of the similar kind, but with the distance
known approximately instead of exactly.
It is a question of a separate investigation whether the approximate distances known from
paired reads is helpful when traversing an A Bruijn graph.


\section{Pseudocode of the assembler}

\todo[inline]{add high-level description of the assembler}


%\section{Schedule}
%\begin{description}
%  \item[April 15] implement earmarking procedure
%  \item[April 18] test earmarking procedure on real data, get general statistics
%  \item[April 20] test different hashing parameters on real data
%  \item[April 22] implement frequency-dependent heuristics
%  \item[April 17] test graph condensation on real data
%  \item[April 30] research into the effects of different hash functions 
%  used to take minimizers
%  \item[May 10] compare the resulting A Bruijn graph with the condensed de 
%  Bruijn graph
%  \item 
%\end{description}

